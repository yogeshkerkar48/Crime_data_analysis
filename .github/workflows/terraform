name: Terraform + ETL Automation
#12345678910
on:
  push:
    branches:
      - main

jobs:
  infra-etl:
    runs-on: ubuntu-latest

    steps:
    # Step 1: Get the repo's code into the runner
      - name: Checkout Code
        uses: actions/checkout@v3
        
    # Step 2: Configure AWS CLI credentials from GitHub Secrets
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ secrets.REGION }}

     # Step 3: Install Terraform in the runner environment
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

     # Step 4: Initialize Terraform (download providers, set up backend, etc.)
      - name: Terraform Init
        run: terraform init

     # Step 5: Validate Terraform configuration syntax and structure
      - name: Terraform Validate  
        run: terraform validate
        
      # Step 6: Apply Terraform changes (deploy/update AWS infrastructure) 
      - name: Terraform Apply
        run: terraform apply -auto-approve

        env:
            TF_VAR_glue_role_arn: ${{ secrets.GLUE_ROLE_ARN }}

        
      # Step 7: Upload the ETL Python script to S3 so Glue can access it
      - name: Upload ETL Script to S3
        run: |
          aws s3 cp etlscript.py s3://rawdatagroup5123123456/scripts/etlscript.py
          echo "ETL script uploaded to S3."

      # Step 8: Start the AWS Glue ETL job
      - name: Start Glue ETL Job
        id: start_etl
        run: |
          JOB_RUN_ID=$(aws glue start-job-run --job-name glue-etl-job201 --query 'JobRunId' --output text)
          echo "ETL JobRunId: $JOB_RUN_ID"
          echo "job_run_id=$JOB_RUN_ID" >> $GITHUB_OUTPUT

       # Step 9: Wait until the Glue job finishes (poll status every 30s)
      - name: Wait for ETL Job Completion
        run: |
          JOB_RUN_ID=${{ steps.start_etl.outputs.job_run_id }}
          while true; do
            STATUS=$(aws glue get-job-run --job-name glue-etl-job201 --run-id "$JOB_RUN_ID" --query 'JobRun.JobRunState' --output text)
            echo "Current ETL job status: $STATUS"
            if [ "$STATUS" == "SUCCEEDED" ]; then
              echo "ETL Job completed successfully."
              break
            elif [ "$STATUS" == "FAILED" ] || [ "$STATUS" == "STOPPED" ]; then
              echo "ETL Job failed or stopped."
              exit 1
            fi
            sleep 30
          done

      # Step 10: Start Glue Crawler to refresh Data Catalog with new data
      - name: Start dimensions Crawler
        run: aws glue start-crawler --name my_etl_crawler

